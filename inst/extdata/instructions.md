## Introduction
The `IBRA` interactive shiny application provides an easy-to-use, general-purpose benchmarking interface for comparing multiple methods in terms of their ability to correctly classify features in a (high-throughput) dataset as "positive" or "negative", as well as in terms of their ability to correctly estimate a continuous target. For example, the app can be used to evaluate the performance of methods aimed at finding differentially expressed or differentially spliced genes between conditions, or to evaluate how well methods manage to estimate the (known) expression of a set of genes. The only formal requirements are that each evaluated method has assigned either (adjusted) p-values or a more general "score" (for example, the estimated expression level that will be compared to the true one) to each feature, and that we know the true status of the features to which the evaluated methods have been applied. The results can be visualized from different perspectives, using different metrics, and can also be stratified by different feature attributes.

## Launching the application
The IBRA app can be launched in two ways:

- With an input object of the type `IBRAData`, generated by the `IBRA` R package. This object contains slots for calculated p-values, adjusted p-values and scores, as well as the truth table. When the application is launched with an input object, all evaluations will be performed using the data in that object. For more information about the `IBRAData` object type, consult the corresponding help page in the `IBRA` R package. 
- Without an input object, either from the `IBRA` R package or from the server (TODO: Put address to server here). In this case, all input data is obtained from text files containing the truth and the results, respectively. These text files are described in more detail in the next section. Note that the `IBRA` R package can be used to convert between IBRAData objects and  correctly formatted text files (see help pages for functions `IBRAData_to_text()` and `IBRAData_from_text()`)

## Input text files
If the `IBRA` app is launched without a data object, two types of input text files are necessary for it to work:

- A "truth" file
- One or more "result" files for the evaluated methods

#### The truth file
The truth file is a tab-delimited text file (with a header line), listing all the features that were investigated (in rows), together with one or more attributes (in columns). The columns are of different types, and are used by the app for different purposes:

- One column contains the feature identifiers. By default, the application uses the first column as identifiers, but this can be modified using the input controls.
- (optional) One column containing a binary truth variable, encoding the true classification of features into "positive" (encoded as 1) and "negative" (encoded as 0). This can be, for example, the true differential expression status of the genes. This column is only necessary to calculate the metrics evaluating the binary classification of features. By default, it is chosen as the first binary column in the truth file, but this can be modified using the input controls. If binary classification should not be evaluated, this can be set to "none".
- (optional) One column containing a continuous truth variable, encoding a characteristic of the data that will be compared to the provided scores. This column is only necessary to calculate the metrics based on comparing continuous scores. By default, it is set to "none", since these metrics may take slightly longer to calculate than the binary classification metrics. This can be modified using the input controls. 
- Additional columns containing categorical variables that can be used to stratify the performance evaluation. 

The table below shows the first lines of an example truth file. Here, we have the columns **feature** (indicating the feature identifier), **status** (the binary true assignment), **logFC** (the true continuous variable corresponding to the scores calculated by the evaluated methods), as well as additional columns representing stratification annotations. 

<img src="screenshot_truth.png" style="width:800px;"/>

#### The result files
The result files contain the p-values, adjusted p-values and scores for the evaluated features. Each file can contain results obtained by one or multiple methods. It is also possible to load multiple result files into the app. Each result file must have a column corresponding to the feature identifier. This column **must** have the same name as in the truth file. In order to correctly interpret the other columns, each column header must be of the form **method:type**, where **type** is either **adjP** (if the column contains adjusted p-values or FDR estimates), **P** (if the column contains nominal p-values), or **score** (if the column contains a general score). 

Nominal p-values will be adjusted by the app, using the Benjamini-Hochberg correction method, as long as the adjusted p-values for the same method have not been previously loaded or are part of the same result file as the p-values. The part of the column name preceding the ":adjP", ":P" or ":score" will be considered the "name" of the method. Please make sure that this name is unique, otherwise only the first one will be included in the results. 

The table below shows the first lines of an example result file, containing nominal p-values, adjusted p-values and scores for several methods. Missing values (NA) are allowed.

<img src="screenshot_results.png" style="width:800px;"/>

### Use of different measure types
The combination of measures that are provided for a given method (P, adjP, score) affects how the performance evaluation will be performed: 

- Calculations of FDR, TPR, number of detections and FPRs at given adjusted p-value thresholds are always calculated based on adjusted p-value inputs (recall that these are calculated from p-values if they are not provided). If adjusted p-values are not available for some methods, they will be excluded from these evaluations.
- The full FDR/TPR and FDR/NBR curves, as well as ROC and FD curves, are calculated from scores or p-values if provided (since these often have a higher resolution than adjusted p-values). If not, adjusted p-values will be used. For FDR/TPR and FDR/NBR curves, if both score/p-value and adjusted p-values are provided, it is necessary that the score/p-value and the adjusted p-values are monotonically related to each other, otherwise the adjusted p-values will be used also for the curves. 
- The continuous evaluations (correlations, scatter plots and deviation plots) are always based on provided scores. If scores are not provided for some methods, they will be excluded from these evaluations.

### Handling missing features

Sometimes, not all features are assigned a score by each of the compared methods. Similarly, some features may not be present in the truth table. The table below tabulates the possible sets of features in a data set. Features that are neither present in the result tables nor in the truth table will not be considered. 

<img src="screenshot_missing.png" style="width:400px;"/>

The default settings of `IBRA` is to consider all features that are present (with non-missing status) in the truth file. Thus, we assume that A = B = 0. By choosing to consider only features shared between the truth and result table, also C and D will be disregarded. The only exception is in the Venn diagrams, where all features are considered (since this is interpretable without a truth). This means that the value represented in the `Number of detections` column in the FDR/NBR plots may differ from the total number of calls in the Venn diagrams. 

## Comparison and evaluation methods
The `IBRA` application calculates several different types of comparison and evaluation metrics, each represented in a separate tab. The available methods are described briefly below. 

- **FDR vs TPR plot**: This plot shows the observed false discovery rate vs the observed true positive rate. If adjusted p-values are provided, it can be calculated for a given set of adjusted p-value cutoffs. It can also be calculated for each possible cutoff to generate an "FDR/TPR curve". Each point in the plot represents one method and one cutoff, and points corresponding to the same method are joined together. If "points" is selected to be displayed in the input panel, and a method controls the FDR (that is, if the observed false discovery rate is lower than or equal to the imposed cutoff), the corresponding point is filled, otherwise it is open. The user can change the imposed adjusted p-value cutoffs using the "FDR thresholds" input in the left-hand control panel.  
- **FDR vs NBR plot**: This plot is similar to the FDR vs TPR plot, but instead of the TPR it shows the number of features classified as positive at given FDR thresholds. 
- **TPR plot**: This plot shows the observed true positive rate for one or more adjusted p-value cutoffs. Each circle represents one method and one cutoff. The user can change the imposed adjusted p-value cutoffs using the "FDR thresholds" input in the left-hand control panel.
- **ROC curves**: This plot shows the ROC (receiver operating characteristic) curves obtained by ranking features according to one of the provided measures (scores if available, otherwise p-values, otherwise adjusted p-values), varying the significance cutoff and calculating the true and false positive rate for each cutoff value. A good method has a ROC curve that passes close to the upper left corner, while a poorly performing method has a ROC curve that lies close to the diagonal line. The user can zoom in to different parts of the ROC curve by modifying the axis limits using the sliders below the plot. 
- **False discovery curves**: This plot is obtained by ranking the features by one of the provided measures (same order of prioritization as for ROC curves), and counting the number of false positives among the top N features, for varying values of N. The maximal value of N can be changed by the user. 
- **Correlation**: This plot shows the correlation between the continuous truth variable (defined by the user in the left-hand sidebar) and the scores for each method. The user can choose between Pearson and Spearman correlation.
- **Scatter plots**: This plot depicts the observed scores against the continuous truth variable (defined by the user in the left-hand sidebar), for each method separately. Axes can be represented on a log-scale.
- **Deviation pots**: This plot shows the distribution of the deviation of the observed scores from the continuous truth defined by the user. The distributions can be shown as violin plots or regular box plots, with or without the individual points overlaid.
- **Venn diagram**: The sets of features classified as "positive" for up to five methods (one of which can be the truth) can be compared using a Venn diagram. The adjusted p-value cutoff for determining significance can be set by the user. The user can also choose whether or not to include the truth in the Venn diagram. If the truth is included, it will be considered as a "perfect" method, assigning an adjusted p-value of 0 to all truly positive features, and an adjusted p-value of 1 to all other features. 

## Input controls
Input controls are located in the sidebar as well as in the individual tabs. By changing one or more of the input parameters, the user can get more precise control of what is shown in the plots. The following general parameters are available:

### Truth-related
- **Select column containing feature identifiers**: The name of the column in the truth and result text files that corresponds to the feature identifiers.
- **Select column containing binary truth**: The name of the column in the truth text file or the provided IBRAData object that contains the binary truth (classification).
- **Select column containing binary truth**: The name of the column in the truth text file or the provided IBRAData object that contains the continuous truth.
- **Select variable to stratify by**: If the uploaded truth file contains columns in addition to the feature identifiers and the truth columns, these will be considered as categorical annotations based on which the results can be stratified. This dropdown menu will automatically appear and be populated with the available columns from the uploaded truth file.
- **Maximum number of levels to show when stratifying**: The maximum number of categories to include if the results are stratified by a variable annotation. The most frequent categories containing both positive and negative instances will be included. 
- **Include 'overall' class when stratifying**: Whether or not the overall results are retained  as one category when the results are stratified by a variable annotation.
- **Show curve and/or points in FDR/TPR plots**: Whether to include lines (full curves) and/or points (for given q-value thresholds) in FDR/TPR and FDR/NBR plots.

### Result-related

- **Select methods**: A list of methods for which the result files provide results. This list will be automatically populated, and augmented if new result files are loaded. Methods can be selected or deselected to include or exclude them from the result visualizations. 
- **Calculate performance based only on features shared between truth and result tables**: In some applications, some methods may not return results for all the features for which we know the true status (e.g., due to filtering). Similarly, the result tables may contain "new" features for which we don't know the true status (e.g., due to merging of original features into complexes). By default, all features available in the truth table will be included in the evaluations. If this box is checked, only features shared between the truth table and each method will be retained.

### General plot-related
- **Select color palette**: Select the color palette that will be used to define colors for the different methods. Some palettes are only applicable if the number of required colors is below a certain threshold. If this threshold is exceeded, the `hue_pal` palette will be used. Note that the number of required colors may be larger than the number of methods, e.g., if results are stratified by an annotation but all strata are shown in the same panel (and thus each method/stratum combination needs a unique color).
- *Display full curve and/or points in FDR/TPR and FDR/NBR plots**: In the FDR/TPR and FDR/NBR plots, the user can choose to include one or both of a limited number of points (results calculated at given adjusted p-value thresholds), or to show the entire curve (considering all thresholds). Note that the points will only be calculated if adjusted p-values are provided.
- **Split plots into panels by stratifying variable**: Whether to split the plots into panels based on the stratifying variable, or to show all results in the same panel.
- **FDR thresholds**: The adjusted p-value cutoffs that are used for the FDR/TPR, FDR/NBR, FPR and TPR plots. One or more thresholds (in the interval [0, 1]) can be chosen. Multiple thresholds must be separated by commas. 
- **Plot height**: The height of the different plots (a numeric value, giving the height in pixels). 
- **Point size**: The size of the circles in the plots.
- **Font size for panel headers**: If the plots are split into panels, this number gives the font size of the panel headers. 

### Specific plot-related
- **Axis limits**: In most plot types, the axis limits can be set using sliders.
- **Download plot**: Download the current plot in pdf format.
- **Download Rdata**: Download the `IBRAPlot` object containing all results needed for plotting (see the `IBRA` package for details).
- **Download tsv**: Download a tab-separated file with the values shown in the plot. 
- **Maximal rank to display** (False discovery curves): The largest number of "top features" shown in the false discovery plots (that is, the upper x-axis limit).
- **Correlation measure** (Correlation): Either Pearson or Spearman, the type of correlation shown in the plot. 
- **Flip axes** (Scatter plots): Flip the x- and y-axes.
- **Log-transform** (Scatter plots): Log-transform the x- and y-axes.
- **Include jittered points** (Deviations): In addition to showing the overall distribution of values, include the individual points.
- **Square deviations** (Deviations): Square the deviations before plotting.
- **Plot type** (Deviations): Whether to show the distribution of deviations as a violin plot or a regular box plot.  
- **Include truth** (Venn diagram): Whether or not the truth should be considered as a (perfect) method in the Venn diagrams. If yes, the "truth" method will be considered to assign an adjusted p-value of 0 to all truly "positive" features, and an adjusted p-value of 1 to the truly "negative" ones. 
- **Adjusted p-value threshold** (Venn diagram): The adjusted p-value threshold that will be used to classify features as positive or negative. The collections of positive features from different methods will be compared in the Venn diagram. 




